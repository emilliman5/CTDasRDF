---
title: "CTDasRDF Project Documentation"
output:
  md_document:
    variant: markdown_github
    
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
This document describes the project data files, scripts, coding conventions, and data modeling decisions for the project.

**CAUTION: If you are reading this document outside of the R environment, the information is likely out of date! 
Knit the .rmd file in the project's Github root /CTDasRDF folder for the latest information. Even then, what you are reading is likely still out of date, but less so.**

Information about the PhUSE cloud server environment is contained in separate documentation.


# Data Files
## SDTM Data Sources
SDTM XPT data files were obtained from the PhUSE CDISCPILOT01 study: https://github.com/phuse-org/phuse-scripts/blob/master/data/sdtm/cdiscpilot01/

Some data augmentation was necessary to test the ontology, so recreated data will not be an exact match to the original .XPT. Discrepancies will be noted at a later time.  

**DM**, **SUPPDM**, **VS** , and some of **EX** are the initial domains used in the project. This may expand if the project timeline permits.

### RDF Files

![Figure: RDF Files and Relations.  Source: /rdf subfolder](images/OntologyRoadmap.png)


1.	**study.ttl** (namespace = study: ) . The main file. It contains the OWL classes and predicates to represent a single study in RDF. It is a metamodel in the sense that instantiation of study.ttl results in an ontology for a single study. study.ttl is heavily BRIDG-based but not entirely as it attempts to better align with how clinical data are generated and used in health care. study.ttl can be thought of as a generic study schema, not associated with any particular protocol. It can be the starting point for each new study and contains the items needed to derive the blank case report form and contributes to the DEFINE file.


2.	**code.ttl** (namspace = code:)  - imported by the study ontology file (study.ttl), code.ttl contains or links to important biomedical concepts that are managed by outside third parties (e.g. CDISC, W3C, and in the future, MedDRA, LOINC, WHO Drug Dictionary, CIMI). All the standard terms needed for the pilot study are contained in code.ttl
  

3.	**cdiscpilot01-protocol.ttl** imports the study.ttl file and contains protocol-specified activities and rules.  Whereas study.ttl describes generic activities and observations in a study, this file describes the specific observations for a particular study and the rules for when to perform them. cdiscpilot01-protocol.ttl includes treatment arm resources and custom analyses. Later development may include the addition of classes like "Protocol-Specified Activity", "Planned Activity", "Scheduled Activity", "Performed Activity", etc.. They are not currently needed for this project and can be derived as owl:Restriction(s) based on the properties of the Activity. For example, a Protocol Specified Activity is any Defined Activity that is associated with a Start Rule; A Planned Activity, is an instance of a Protocol Specified Activity that is associated with a Subject, ....etc. [Note: These items are also of importance to the PhUSE "Protocol as RDF" project. May include information like the location of information on the CRF.

4.	**cdiscpilot01.ttl** imports the protocol file above (#3) and adds instance data for the first 3 subjects in the pilot study. Instance data is manually added to the .ttl file as needed for testing and development. The file **cdiscpilot01-R.ttl** is from first attempts to convert XPT source data using R. It will be replaced with a file from the SMS process: **cdiscpilot01-SMS.ttl** (mapped using SMS, uploaded to Stardog, exported to TTL). The two files are compared to ensure the original hard-coded ontology instance data matches those created by the data conversion process. 


5.	To get the data out in a format that we want (e.g. SDTM) we need to link all this information to an SDTM ontology. this is accomplished at the protocol level via the **sdtm-cd01p.ttl** file, from which one can automate the creation of define.xml and eventually the blank case report form.


6.	At the instance level, we take the instance data (cdiscpilot01.ttl) and link it to the sdtm ontology (see sdtm-cdisc01.ttl). This file is used  to generate high quality, highly standardized SDTM domains (DM, VS, and SUPPDM) using embedded SPARQL queries (i.e. spin: rules). Note that the instance data file also contains limited exposure information needed to derived certain DM variables (RFXSTDTC and RFXENDTC) although representing full exposure data to generate the EX domain is currently out of scope. 



#### Additional Files

* **sdtm.ttl**
    - Mini study ontology in RDF/OWL. Variable Name, Label, Role. Used to generate: 1.  SDTM domains in the prototype 2. DEFINE XML . 

* **sdtmig-3-1-3.ttl**
    - SDTM IG version 3.1.3.  Used to generate: 1.  SDTM domains in the prototype 2. DEFINE XML 

* **sdtm-cdisc01.ttl**
    - Links cdiscpilot01.ttl with study.ttl for round-tripping the data back to the SDTM standard.
    
* **sdtm-cd01p.ttl**
    - Specific to implmentation of a specific protocol. Used where  SDTM provides flexibiity in implementation. Example: Comment for USUBJID: "Concatenation of STUDYID, DM.SITEID and DM.SUBJID" .  This is the "protocol-specific SDTM implemntation file." Used in generation of DEFINE XML.

# Data Conversion

## Background
Data conversion from XPT to graph was originally used R script. In September 2017 the project switched from use of  Egon Willighagen's R package rrdf <https://github.com/egonw/rrdf> to the redland package <https://cran.r-project.org/web/packages/redland/>. This change removes dependencies on rJava and provides a data conversion mechanism that relies on a package available from CRAN.

Following discussions at the PhUSE CSS in March 2018, data conversion is moving from R to use of Stardog Mapping Syntax (SMS). SMS can be converted back to R2RML, the open source W3C standard.

Additional details about the SMS mapping will be placed in this document in the coming weeks. R content was removed 14Mar18.



# R Scripts
To be added: A description of the various R scripts used for processing and visualizing the data. 

## Data Preparation
* **DM_imputeCSV.R**
  * Converts the source DM.XPT to CSV and imputes values needed to test the model. Example: Setting the death flag and date for Subject 1. Based on the original DM_impute.R.

## Validation
* **CompTriples-Shiny.R**
    * R Shiny App to facilitate comparison of the .TTL file created by the SMS process with the ontology instance data created by AO using TopBraid.

## Visualization
* **Person-MultLevel-VisNetwork-ForceNetwork.R**
    * Triples attached to Person_1 in cdiscpilot01.TTL as a force network graph using visNetwork. Functionality includes: selection by node or group, node selection by mouse click, mouseover of relations.
    NOTE: OUTDATED: Must be updated to use new IRI specifications based on hashes.

# Coding Conventions
## Variable naming
* CamelCase for classes
* CamelCase_(n) for instances of classes.


## Data Types
### Dates and Date Processing
NOTE: This section will be updated after implications of SMS conversion process become apparent.

Date values are evaluated during the conversion to RDF.

* Date values (as represented in fields like rfstdtc, rfendtc, rfxendtc, etc.) with complete and valid year, month, and data values are typed as xsd:date.
* Incomplete date values or values that have incomplete dateTime values (missing seconds, for example) are typed as xsd:string, since xsd:dateTime would be semantically incorrect. See discussion at: <http://stackoverflow.com/questions/25165456/is-this-a-valid-xsddatetime-if-so-why> At a later time, incomplete date values may be coded to their corresponding components (year,day,hour..) using the TIME ontology (not currently implemented).

Dates are assigned a URI by first combining all dates (during dev, only a subset!) from the domains being processed (DM, SUPPDM, VS, EX) into a single column, sorting by date, then assigning a number. This is accomplished in the function createDateDict() within createFrag_F.R. It is called from buildRDF-Driver.R after the domains have been imported from the XPT. To add new domains and date columns you must edit createDateDict().

After the list of all dates and their URIs is created, the date URI's must be merged back into the individual domains. This is accomplished using addDateFrag(), called from <domain>_Frag.R , one call for each date column. TODO: Make the assignments back to the respective domains within createDateDic(), removing the need to call addDateFrag.


# Data Modeling Decisions    
## Introduction
The traditional SDTM data model is limited by its row x column structure and modeling decisions that can be solved by the RDF ontologies and a multi-dimensional data structure. This section of the project wiki documents the details of the RDF data model and the issues in SDTM that are resolved using Linked Data approaches. Expect this page to change as the model evolves during the project.

"SDTM model" refers to the various approved SDTM versions published by CDISC and "RDF Model" refers to the model under development as part of this project.

## Treatment Arms
SDTM allows "fake" arms, like SCRNFL (screen failure) and NOT TREATED, for valid values for Arm and ArmCD. In the RDF model we treat them as real Arms so we can do the roundtripping back out to SDTM from RDF, but we exclude them from participating as values of Outcomes for "Randomization Activity", since no one is randomized to a screen failure or Not Treated arm.

## Observations
SDTM recognizes three types of Observations:

1. Findings
2. Interventions
3. Events

### Findings and Interventions
In stark contrast to the SDTM Model, the RDF Model defines Findings as a type of Intervention, thus providing a single standard approach to document the process that leads to either a Finding or a therapeutic Intervention. For example, some procedures like cardiac catheterization involve both concepts: a) Finding: determines there is a blocked artery b) (therapuetic) Intervention: inserts a stent to keep artery open

All Findings are Interventions in the sense that "someone has to do something" (that one wouldn't ordinarily do in the course of the subject's daily routine, i.e. to intervene) to make and record the Finding. This is true for simple measures like temperature through to more complex tests like a biopsy. It is often important to document the more complex procedures. For example, to record collection of a biospecimen collection and its processing, and/or the use of a medical device.

### Events
The RDF model defines certain Events like Adverse Events not as Observations, but as Medical Conditions that are identified as an AsessmentOutcome. The SDTM model does not capture the Assessment information that led to the Outcome. In SDTM, assessment information is usually either 1) lumped together with observation data, 2) saved in SUPPQUAL, or 3) relegated to custom domains. The RDF model fixes this modeling problem **[TODO: ADD PRECISELY HOW]** while making it challenging to recreate SDTM datasets that perpetuate the modeling error. Automation across submissions may also prove difficult. **[TODO: ADD MORE HERE ABOUT THE AUTOMATION ISSUE]**

### Activities [2017-11-02]
Measurement activites like Blood Pressure, Pulse, etc. are considered subActivities of a visit, that occur during a visit.  BP, Pulse are a subClass of Visit Activity, as shown in the hierarchy:

 Activity --> Study Activity -- Visit Activity

The predicate study:subActivity makes this link.


### VS : Body Position, Start Rules, Test sequence [updated 2017-11-02]
Each subject has two AssumeBodyPosition activities, 1 lying and 1 standing

Sequence:

1. After lying 5 minutes:        SBP1, DBP1, Pulse1
2. Stand. After standing 1 min:  SBP2, DBP2, Pulse2
3. Still standing: after 3 min:  SBP3, DBP3, Pulse3
 
Both standing activities are associated with the same standing "event" : AssumeBodyPositionStanding_(n).  The person stands (assumes standing position), then the two start rules come into play: StartRuleStanding1_(n)  (1 minute stand rule),  followed later by StartRuleStanding3_(n)  (3 minute standing rule).

This sequence is not explicit in the SDTM data. For data conversion purposes, it is derived by a combination of the USUBJID, VISIT, and VSPTNUM fields during triple creation.

Start Rules indicate the pre-requisite activities. The measurements conducted in the standing position are preceded by lying down, then the subject stands for 1 min and measurements are conducted. Then the 3min measurements are conducted. This means that the **AssumeBodyPositionStanding_1** triples have a prequisite **StartRuleLying5_1** , as illustrated in the following set of triples:

THE FOLLOWING TRIPLES ARE OUTDATED AS OF 14MAR18:

```
cdiscpilot01:AssumeBodyPositionStanding_1 ;
  rdf:type custom:AssumeBodyPositionStanding ;
  skos:prefLabel "assume standing position"^^xsd:string ;
  study:activityStatus code:ActivityStatus_1 ;
  study:hasCode custom:AssumeBodyPositionStanding ;
  study:hasDate cdiscpilot01:Date_19 ;
  study:hasStartRule cdiscpilot01:StartRuleLying5_1 ;
  study:outcome sdtmterm:#C71148.C62166 . 
```

### Miscellaneous
SDTM variables --CAT and --SCAT have no consistent meaning across submissions and so cannot be modeled consistently in the RDF ontology. This is also true for the entire RELREC domain which relates records with each other **[TODO:ADD MORE DETAIL ON CURRENT USE]**. In the semantically consistent the RDF model the concept of a record disappears where concepts and data values are related by design.

        